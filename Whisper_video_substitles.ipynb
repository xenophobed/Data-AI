{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNYxJMGY0NFLqQvPZXJKFU7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b273c250aafd44eb844c0761bc3f9439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "tiny.en",
              "tiny",
              "base.en",
              "base",
              "small.en",
              "small",
              "medium.en",
              "medium",
              "large-v1",
              "large-v2",
              "large-v3",
              "large"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Model:",
            "description_tooltip": null,
            "disabled": false,
            "index": 3,
            "layout": "IPY_MODEL_fc9e048583d640e789daba058ca1ccdd",
            "style": "IPY_MODEL_608f3f7da72c423ab199f6a6d3f8098c"
          }
        },
        "fc9e048583d640e789daba058ca1ccdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "608f3f7da72c423ab199f6a6d3f8098c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d486d52c3d3c4429882e4edb2df7aba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "CPU",
              "AUTO"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Device:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_578843efe5394ec480d7d95dabc61210",
            "style": "IPY_MODEL_8e920fa326564f2186fdf268448bca71"
          }
        },
        "578843efe5394ec480d7d95dabc61210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e920fa326564f2186fdf268448bca71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fffb44e2b2cd446e9a5121d710241cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Video:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_47fca361965d465db7c3b3b43dff82a0",
            "placeholder": "Type link for video",
            "style": "IPY_MODEL_44263add96b547b088c677da5918a6e3",
            "value": "https://youtu.be/5bs9XoTac88"
          }
        },
        "47fca361965d465db7c3b3b43dff82a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44263add96b547b088c677da5918a6e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38dac3cfdafb4261bb375aa9f4f35676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VideoModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VideoModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VideoView",
            "autoplay": true,
            "controls": true,
            "format": "mp4",
            "height": "400",
            "layout": "IPY_MODEL_35988ed18b394c9e8e1cd7e4e16e2b1d",
            "loop": false,
            "width": "400"
          }
        },
        "35988ed18b394c9e8e1cd7e4e16e2b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c3474270f0c47178f70ba84e2ad2659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "tiny.en",
              "tiny",
              "base.en",
              "base",
              "small.en",
              "small",
              "medium.en",
              "medium",
              "large-v1",
              "large-v2",
              "large-v3",
              "large"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Model:",
            "description_tooltip": null,
            "disabled": false,
            "index": 3,
            "layout": "IPY_MODEL_c1c93793ce594772a676a07e1c8ca1c6",
            "style": "IPY_MODEL_995afcf4608c4d1caf8e848452c2193d"
          }
        },
        "c1c93793ce594772a676a07e1c8ca1c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "995afcf4608c4d1caf8e848452c2193d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca8f13cfd9074ce5868e2989e4b6d436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SelectModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SelectModel",
            "_options_labels": [
              "transcribe",
              "translate"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "SelectView",
            "description": "Select task:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_b9d9dec08c8044af92433750b8fee542",
            "rows": 5,
            "style": "IPY_MODEL_388979d05aed4d38b8eb23f33658ef3b"
          }
        },
        "b9d9dec08c8044af92433750b8fee542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "388979d05aed4d38b8eb23f33658ef3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xenophobed/Notebooks/blob/main/Whisper_video_substitles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt9RluwLcLQ_",
        "outputId": "1ea36308-8c39-498c-a467-01ccf903208b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-25 08:27:37 URL:https://raw.githubusercontent.com/PacktPublishing/Learn-OpenAI-Whisper/main/Chapter06/utils.py [11251/11251] -> \"utils.py\" [1]\n"
          ]
        }
      ],
      "source": [
        "!wget -nv \"https://github.com/PacktPublishing/Learn-OpenAI-Whisper/raw/main/Chapter06/utils.py\" -O utils.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q cohere openai tiktoken\n",
        "%pip install -q \"openvino>=2023.1.0\"\n",
        "%pip install -q \"python-ffmpeg<=1.0.16\" moviepy transformers --extra-index-url https://download.pytorch.org/whl/cpu\n",
        "%pip install -q \"git+https://github.com/garywu007/pytube.git\"\n",
        "%pip install -q gradio\n",
        "%pip install -q \"openai-whisper==20231117\" --extra-index-url https://download.pytorch.org/whl/cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3uqBuXMcXi4",
        "outputId": "739c413e-059d-4aee-c4c1-c83ff505639a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/221.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.3/221.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/373.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.5/373.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pytube (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from whisper import _MODELS\n",
        "import ipywidgets as widgets\n",
        "\n",
        "model_id = widgets.Dropdown(\n",
        "    options=list(_MODELS),\n",
        "    value='base',\n",
        "    description='Model:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "model_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b273c250aafd44eb844c0761bc3f9439",
            "fc9e048583d640e789daba058ca1ccdd",
            "608f3f7da72c423ab199f6a6d3f8098c"
          ]
        },
        "id": "qP-_YG-KfZa-",
        "outputId": "27b7bb2a-3159-4347-eaf7-572a8d013f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Model:', index=3, options=('tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'm…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b273c250aafd44eb844c0761bc3f9439"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# model = whisper.load_model(model_id.value)\n",
        "model = whisper.load_model(model_id.value, \"cpu\")\n",
        "model.eval()\n",
        "pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlpY4cS_fopg",
        "outputId": "df55af70-5ca5-4089-a880-c08301614948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:01<00:00, 89.6MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "WHISPER_ENCODER_OV = Path(f\"whisper_{model_id.value}_encoder.xml\")\n",
        "WHISPER_DECODER_OV = Path(f\"whisper_{model_id.value}_decoder.xml\")"
      ],
      "metadata": {
        "id": "smPLkb2wftpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import openvino as ov\n",
        "\n",
        "mel = torch.zeros((1, 80 if 'v3' not in model_id.value else 128, 3000))\n",
        "audio_features = model.encoder(mel)\n",
        "if not WHISPER_ENCODER_OV.exists():\n",
        "    encoder_model = ov.convert_model(model.encoder, example_input=mel)\n",
        "    ov.save_model(encoder_model, WHISPER_ENCODER_OV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iClE9U2NfzjY",
        "outputId": "ee8f9384-341e-4458-c9d5-59d25f3a6c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/model.py:166: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert x.shape[1:] == self.positional_embedding.shape, \"incorrect audio shape\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from typing import Optional, Tuple\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "def attention_forward(\n",
        "        attention_module,\n",
        "        x: torch.Tensor,\n",
        "        xa: Optional[torch.Tensor] = None,\n",
        "        mask: Optional[torch.Tensor] = None,\n",
        "        kv_cache: Optional[Tuple[torch.Tensor, torch.Tensor]] = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Override for forward method of decoder attention module with storing cache values explicitly.\n",
        "    Parameters:\n",
        "      attention_module: current attention module\n",
        "      x: input token ids.\n",
        "      xa: input audio features (Optional).\n",
        "      mask: mask for applying attention (Optional).\n",
        "      kv_cache: dictionary with cached key values for attention modules.\n",
        "      idx: idx for search in kv_cache.\n",
        "    Returns:\n",
        "      attention module output tensor\n",
        "      updated kv_cache\n",
        "    \"\"\"\n",
        "    q = attention_module.query(x)\n",
        "\n",
        "    if xa is None:\n",
        "        # hooks, if installed (i.e. kv_cache is not None), will prepend the cached kv tensors;\n",
        "        # otherwise, perform key/value projections for self- or cross-attention as usual.\n",
        "        k = attention_module.key(x)\n",
        "        v = attention_module.value(x)\n",
        "        if kv_cache is not None:\n",
        "            k = torch.cat((kv_cache[0], k), dim=1)\n",
        "            v = torch.cat((kv_cache[1], v), dim=1)\n",
        "        kv_cache_new = (k, v)\n",
        "    else:\n",
        "        # for cross-attention, calculate keys and values once and reuse in subsequent calls.\n",
        "        k = attention_module.key(xa)\n",
        "        v = attention_module.value(xa)\n",
        "        kv_cache_new = (None, None)\n",
        "\n",
        "    wv, qk = attention_module.qkv_attention(q, k, v, mask)\n",
        "    return attention_module.out(wv), kv_cache_new\n",
        "\n",
        "\n",
        "def block_forward(\n",
        "    residual_block,\n",
        "    x: torch.Tensor,\n",
        "    xa: Optional[torch.Tensor] = None,\n",
        "    mask: Optional[torch.Tensor] = None,\n",
        "    kv_cache: Optional[Tuple[torch.Tensor, torch.Tensor]] = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Override for residual block forward method for providing kv_cache to attention module.\n",
        "      Parameters:\n",
        "        residual_block: current residual block.\n",
        "        x: input token_ids.\n",
        "        xa: input audio features (Optional).\n",
        "        mask: attention mask (Optional).\n",
        "        kv_cache: cache for storing attention key values.\n",
        "      Returns:\n",
        "        x: residual block output\n",
        "        kv_cache: updated kv_cache\n",
        "\n",
        "    \"\"\"\n",
        "    x0, kv_cache = residual_block.attn(residual_block.attn_ln(\n",
        "        x), mask=mask, kv_cache=kv_cache)\n",
        "    x = x + x0\n",
        "    if residual_block.cross_attn:\n",
        "        x1, _ = residual_block.cross_attn(\n",
        "            residual_block.cross_attn_ln(x), xa)\n",
        "        x = x + x1\n",
        "    x = x + residual_block.mlp(residual_block.mlp_ln(x))\n",
        "    return x, kv_cache\n",
        "\n",
        "\n",
        "\n",
        "# update forward functions\n",
        "for idx, block in enumerate(model.decoder.blocks):\n",
        "    block.forward = partial(block_forward, block)\n",
        "    block.attn.forward = partial(attention_forward, block.attn)\n",
        "    if block.cross_attn:\n",
        "        block.cross_attn.forward = partial(attention_forward, block.cross_attn)\n",
        "\n",
        "\n",
        "def decoder_forward(decoder, x: torch.Tensor, xa: torch.Tensor, kv_cache: Optional[Tuple[Tuple[torch.Tensor, torch.Tensor]]] = None):\n",
        "    \"\"\"\n",
        "    Override for decoder forward method.\n",
        "    Parameters:\n",
        "      x: torch.LongTensor, shape = (batch_size, <= n_ctx) the text tokens\n",
        "      xa: torch.Tensor, shape = (batch_size, n_mels, n_audio_ctx)\n",
        "           the encoded audio features to be attended on\n",
        "      kv_cache: Dict[str, torch.Tensor], attention modules hidden states cache from previous steps\n",
        "    \"\"\"\n",
        "    if kv_cache is not None:\n",
        "        offset = kv_cache[0][0].shape[1]\n",
        "    else:\n",
        "        offset = 0\n",
        "        kv_cache = [None for _ in range(len(decoder.blocks))]\n",
        "    x = decoder.token_embedding(\n",
        "        x) + decoder.positional_embedding[offset: offset + x.shape[-1]]\n",
        "    x = x.to(xa.dtype)\n",
        "    kv_cache_upd = []\n",
        "\n",
        "    for block, kv_block_cache in zip(decoder.blocks, kv_cache):\n",
        "        x, kv_block_cache_upd = block(x, xa, mask=decoder.mask, kv_cache=kv_block_cache)\n",
        "        kv_cache_upd.append(tuple(kv_block_cache_upd))\n",
        "\n",
        "    x = decoder.ln(x)\n",
        "    logits = (\n",
        "        x @ torch.transpose(decoder.token_embedding.weight.to(x.dtype), 1, 0)).float()\n",
        "\n",
        "    return logits, tuple(kv_cache_upd)\n",
        "\n",
        "\n",
        "\n",
        "# override decoder forward\n",
        "model.decoder.forward = partial(decoder_forward, model.decoder)"
      ],
      "metadata": {
        "id": "hVC3V3KPf18q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = torch.ones((5, 3), dtype=torch.int64)\n",
        "logits, kv_cache = model.decoder(tokens, audio_features, kv_cache=None)\n",
        "\n",
        "tokens = torch.ones((5, 1), dtype=torch.int64)\n",
        "\n",
        "if not WHISPER_DECODER_OV.exists():\n",
        "    decoder_model = ov.convert_model(model.decoder, example_input=(tokens, audio_features, kv_cache))\n",
        "    ov.save_model(decoder_model, WHISPER_DECODER_OV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix7bQBzSgahl",
        "outputId": "13ab934b-07de-43e2-b980-8b277f5cea54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py:168: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  if a.grad is not None:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "core = ov.Core()"
      ],
      "metadata": {
        "id": "x9ECgeyzgccJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "device = widgets.Dropdown(\n",
        "    options=core.available_devices + [\"AUTO\"],\n",
        "    value='AUTO',\n",
        "    description='Device:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d486d52c3d3c4429882e4edb2df7aba3",
            "578843efe5394ec480d7d95dabc61210",
            "8e920fa326564f2186fdf268448bca71"
          ]
        },
        "id": "_Ck0nDlZhzWW",
        "outputId": "0b26763b-b677-49b0-a10d-5b965b722b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Device:', index=1, options=('CPU', 'AUTO'), value='AUTO')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d486d52c3d3c4429882e4edb2df7aba3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import patch_whisper_for_ov_inference, OpenVINOAudioEncoder, OpenVINOTextDecoder\n",
        "\n",
        "patch_whisper_for_ov_inference(model)\n",
        "\n",
        "model.encoder = OpenVINOAudioEncoder(core, WHISPER_ENCODER_OV, device=device.value)\n",
        "model.decoder = OpenVINOTextDecoder(core, WHISPER_DECODER_OV, device=device.value)"
      ],
      "metadata": {
        "id": "dEDqdQevh09d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "# VIDEO_LINK = \"https://youtu.be/kgL5LBM-hFI\"\n",
        "VIDEO_LINK = \"https://youtu.be/5bs9XoTac88\"\n",
        "link = widgets.Text(\n",
        "    value=VIDEO_LINK,\n",
        "    placeholder=\"Type link for video\",\n",
        "    description=\"Video:\",\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "link"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fffb44e2b2cd446e9a5121d710241cc3",
            "47fca361965d465db7c3b3b43dff82a0",
            "44263add96b547b088c677da5918a6e3"
          ]
        },
        "id": "6v2y0BWIh2_-",
        "outputId": "f0c86a55-32ad-4979-b351-b055fb71334b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='https://youtu.be/5bs9XoTac88', description='Video:', placeholder='Type link for video')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fffb44e2b2cd446e9a5121d710241cc3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = Path(\"downloaded_video.mp4\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KaL16VhYiCKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import get_audio\n",
        "\n",
        "audio, duration = get_audio(output_file)\n",
        "\n",
        "import ipywidgets as widgets\n",
        "widgets.Video.from_file(output_file, loop=False, width=400, height=400)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250,
          "referenced_widgets": [
            "38dac3cfdafb4261bb375aa9f4f35676",
            "35988ed18b394c9e8e1cd7e4e16e2b1d"
          ]
        },
        "id": "BdOyyQjkmmBS",
        "outputId": "ebac715d-74ef-49a0-e393-9989ca1b05a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Video(value=b'\\x00\\x00\\x00\\x1cftypmp42\\x00\\x00\\x00\\x01isommp41mp42\\x00\\x00\\xf4\\xb9moov\\x00\\x00\\x00lmvhd\\x00\\x0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38dac3cfdafb4261bb375aa9f4f35676"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from whisper import _MODELS\n",
        "import ipywidgets as widgets\n",
        "\n",
        "model_id = widgets.Dropdown(\n",
        "    options=list(_MODELS),\n",
        "    value='base',\n",
        "    description='Model:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "model_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2c3474270f0c47178f70ba84e2ad2659",
            "c1c93793ce594772a676a07e1c8ca1c6",
            "995afcf4608c4d1caf8e848452c2193d"
          ]
        },
        "id": "ltO2wFO-oIF5",
        "outputId": "12a8db83-d9c3-45ee-bcbc-996697d9d564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Model:', index=3, options=('tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'm…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c3474270f0c47178f70ba84e2ad2659"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task = widgets.Select(\n",
        "    options=[\"transcribe\", \"translate\"],\n",
        "    value=\"translate\",\n",
        "    description=\"Select task:\",\n",
        "    disabled=False\n",
        ")\n",
        "task"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110,
          "referenced_widgets": [
            "ca8f13cfd9074ce5868e2989e4b6d436",
            "b9d9dec08c8044af92433750b8fee542",
            "388979d05aed4d38b8eb23f33658ef3b"
          ]
        },
        "id": "HCVnuYf9oieb",
        "outputId": "0d6553ce-e75c-4a89-d205-cea09184bfe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Select(description='Select task:', index=1, options=('transcribe', 'translate'), value='translate')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca8f13cfd9074ce5868e2989e4b6d436"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y62tPQaWomYS",
        "outputId": "89f60245-5d4d-4cb5-9b5f-54018f1e3fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    model = model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "VDuY21zSqGRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcription = model.transcribe(audio, fp16=torch.cuda.is_available(), task=task.value)"
      ],
      "metadata": {
        "id": "7lcaTYuuosAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import prepare_srt\n",
        "\n",
        "srt_lines = prepare_srt(transcription, filter_duration=duration)\n",
        "# save transcription\n",
        "with output_file.with_suffix(\".srt\").open(\"w\") as f:\n",
        "    f.writelines(srt_lines)"
      ],
      "metadata": {
        "id": "JsThWdw7pzaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\".join(srt_lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA-mhNKIqzPg",
        "outputId": "bd4c1338-9ff9-4106-af69-7b9da07734b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "00:00:00,000 --> 00:00:06,400\n",
            " Hey, I'm Sina and I'm excited to introduce you to Eureka.\n",
            "\n",
            "2\n",
            "00:00:06,400 --> 00:00:12,160\n",
            " Eureka is the world's first AI doctor that can order labs and deliver care in the real\n",
            "\n",
            "3\n",
            "00:00:12,160 --> 00:00:13,960\n",
            " world.\n",
            "\n",
            "4\n",
            "00:00:13,960 --> 00:00:16,040\n",
            " Let me show you Eureka in action.\n",
            "\n",
            "5\n",
            "00:00:16,040 --> 00:00:20,920\n",
            " Eureka gives you fast and personalized care for your conditions.\n",
            "\n",
            "6\n",
            "00:00:20,920 --> 00:00:25,600\n",
            " Eureka has unlimited time, attention and patience.\n",
            "\n",
            "7\n",
            "00:00:25,600 --> 00:00:32,240\n",
            " When Eureka learns that I have hypothyroidism, it knows exactly what questions to ask next.\n",
            "\n",
            "8\n",
            "00:00:32,240 --> 00:00:38,200\n",
            " Eureka can do this because it thinks like a doctor and reasons like a detective.\n",
            "\n",
            "9\n",
            "00:00:38,200 --> 00:00:43,800\n",
            " In a few minutes, Eureka discovers that I'm taking too little medication and then recommends\n",
            "\n",
            "10\n",
            "00:00:43,800 --> 00:00:46,840\n",
            " an adjustment to improve my symptoms.\n",
            "\n",
            "11\n",
            "00:00:46,840 --> 00:00:52,080\n",
            " Eureka then orders follow-up labs for the future to monitor my improvements.\n",
            "\n",
            "12\n",
            "00:00:52,080 --> 00:00:56,840\n",
            " For any care starts, a licensed physician reviews Eureka's recommendations to make\n",
            "\n",
            "13\n",
            "00:00:56,840 --> 00:00:59,560\n",
            " sure everything is in order.\n",
            "\n",
            "14\n",
            "00:00:59,560 --> 00:01:05,040\n",
            " Working with Eureka is almost 90 times faster than traditional and specialist care in the\n",
            "\n",
            "15\n",
            "00:01:05,040 --> 00:01:06,040\n",
            " US.\n",
            "\n",
            "16\n",
            "00:01:06,040 --> 00:01:08,120\n",
            " And users love Eureka.\n",
            "\n",
            "17\n",
            "00:01:08,120 --> 00:01:13,560\n",
            " Nine out of ten users want to continue with Eureka's suggested care.\n",
            "\n",
            "18\n",
            "00:01:13,560 --> 00:01:19,000\n",
            " And maybe that's why Eureka also receives three times more excellent care ratings than\n",
            "\n",
            "19\n",
            "00:01:19,000 --> 00:01:21,120\n",
            " the average care visit.\n",
            "\n",
            "20\n",
            "00:01:21,120 --> 00:01:27,040\n",
            " We built Eureka to take symptoms seriously and to give incredible care.\n",
            "\n",
            "21\n",
            "00:01:27,040 --> 00:01:30,440\n",
            " Twenty-four hours a day, seven days a week.\n",
            "\n",
            "22\n",
            "00:01:30,440 --> 00:01:33,840\n",
            " Eureka currently specializes in endocrine conditions.\n",
            "\n",
            "23\n",
            "00:01:33,840 --> 00:01:39,480\n",
            " And if you have diabetes or a thyroid condition, you can get care now by visiting Eurekahealth.com.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /tmp/gradio"
      ],
      "metadata": {
        "id": "8aIi2mlMq28Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from pytube import YouTube\n",
        "from utils import prepare_srt\n",
        "from utils import get_audio\n",
        "\n",
        "def transcribe(url, task):\n",
        "    output_file = Path(\"downloaded_video.mp4\")\n",
        "    yt = YouTube(url)\n",
        "    yt.streams.get_highest_resolution().download(filename=output_file)\n",
        "    audio, duration = get_audio(output_file)\n",
        "    transcription = model.transcribe(audio, fp16=torch.cuda.is_available(), task=task.lower())\n",
        "    srt_lines = prepare_srt(transcription, duration)\n",
        "    with output_file.with_suffix(\".srt\").open(\"w\") as f:\n",
        "        f.writelines(srt_lines)\n",
        "    return [str(output_file), str(output_file.with_suffix(\".srt\"))]\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    transcribe,\n",
        "    [gr.Textbox(label=\"YouTube URL\"), gr.Radio([\"Transcribe\", \"Translate\"], value=\"Transcribe\")],\n",
        "    \"video\",\n",
        "    examples=[[\"https://youtu.be/5bs9XoTac88\", \"Translate\"],\n",
        "              [\"https://youtu.be/kgL5LBM-hFI\", \"Transcribe\"]],\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "try:\n",
        "    demo.launch(debug=True)\n",
        "except Exception:\n",
        "    demo.launch(share=True, debug=True)\n",
        "# if you are launching remotely, specify server_name and server_port\n",
        "# demo.launch(server_name='your server name', server_port='server port in int')\n",
        "# Read more in the docs: https://gradio.app/docs/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "c4s-AdOMrJpZ",
        "outputId": "21b2e973-d11d-49b6-bc16-24b17d804d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://0c7cfe114082b16794.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0c7cfe114082b16794.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://0c7cfe114082b16794.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OHD-NxcBrLf2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}